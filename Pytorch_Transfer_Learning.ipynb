{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing required Libraries and Modules","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.ion()\n\nimport torch\nfrom torch.utils.data.dataset import random_split\nfrom torch.utils.data.dataloader import DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\ncudnn.benchmark = True\n\nimport torchvision\nfrom torchvision import models\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\ntorch.manual_seed(42)\n\nimport time\nimport copy\nimport glob\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-08-05T10:21:16.006974Z","iopub.execute_input":"2022-08-05T10:21:16.007705Z","iopub.status.idle":"2022-08-05T10:21:27.117864Z","shell.execute_reply.started":"2022-08-05T10:21:16.007617Z","shell.execute_reply":"2022-08-05T10:21:27.116842Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Setting paths to training images","metadata":{}},{"cell_type":"code","source":"TRAIN_FOLDER_PATH = \"/kaggle/input/intel-image-classification/seg_train/seg_train\"","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:35.489755Z","iopub.execute_input":"2022-08-05T10:22:35.491052Z","iopub.status.idle":"2022-08-05T10:22:35.495879Z","shell.execute_reply.started":"2022-08-05T10:22:35.491004Z","shell.execute_reply":"2022-08-05T10:22:35.494949Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Finding Mean and SD for Normalization","metadata":{}},{"cell_type":"code","source":"%%time\n\ntrain = ImageFolder(\n            TRAIN_FOLDER_PATH,\n            transform = tt.Compose([\n                tt.Resize(64),\n                tt.RandomCrop(64),\n                tt.ToTensor()\n            ])\n        )\n\ntrain_dl_for_mean_sd = DataLoader(\n                            dataset = train,\n                            batch_size = 108,\n                            shuffle = True,\n                            num_workers = 2,\n                            pin_memory = True\n                        )\n\nsum, ss, batches = 0, 0, 0\nfor data, _ in train_dl_for_mean_sd :\n    sum += torch.mean(data, dim = ([0,2,3]))\n    ss += torch.mean(data**2, dim =([0,2,3]))\n    batches += 1\nmean = sum / batches\nstd = ((ss / batches) - mean**2)**0.5\nprint( mean, std )","metadata":{"execution":{"iopub.status.busy":"2022-08-05T06:31:11.757219Z","iopub.execute_input":"2022-08-05T06:31:11.757602Z","iopub.status.idle":"2022-08-05T06:32:01.650757Z","shell.execute_reply.started":"2022-08-05T06:31:11.757566Z","shell.execute_reply":"2022-08-05T06:32:01.649500Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Transforming the Images","metadata":{}},{"cell_type":"code","source":"mean = (0.4302, 0.4575, 0.4539)\nstd = (0.2483, 0.2467, 0.2806)\nmean_sd = ( mean, std )\n\ntrain_val_transform = tt.Compose([\n                            tt.Resize(64),\n                            tt.RandomCrop(64),\n                            tt.RandomHorizontalFlip(),\n                            tt.ToTensor(),\n                            tt.Normalize(*mean_sd, inplace = True)\n                        ])\n\ntrain = ImageFolder(TRAIN_FOLDER_PATH, train_val_transform)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:41.564771Z","iopub.execute_input":"2022-08-05T10:22:41.565130Z","iopub.status.idle":"2022-08-05T10:22:43.914112Z","shell.execute_reply.started":"2022-08-05T10:22:41.565099Z","shell.execute_reply":"2022-08-05T10:22:43.913050Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Train - Validation Split","metadata":{}},{"cell_type":"code","source":"VAL_RATIO = 0.2\nVAL_SIZE = int(len(train)*VAL_RATIO)\nTRAIN_SIZE = len(train) - VAL_SIZE\ntrain_data, val_data = random_split(train, [TRAIN_SIZE, VAL_SIZE])","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:43.917961Z","iopub.execute_input":"2022-08-05T10:22:43.918459Z","iopub.status.idle":"2022-08-05T10:22:43.927828Z","shell.execute_reply.started":"2022-08-05T10:22:43.918431Z","shell.execute_reply":"2022-08-05T10:22:43.926824Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# DataLoaders","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 72\n\ntrain_data_loader = DataLoader(\n                            dataset = train_data,\n                            batch_size = BATCH_SIZE,\n                            shuffle = True,\n                            num_workers = 2,\n                            pin_memory = True\n                        )\n\nvalid_data_loader = DataLoader(\n                            dataset = val_data,\n                            batch_size = BATCH_SIZE,\n                            shuffle = True,\n                            num_workers = 2,\n                            pin_memory = True\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:45.060238Z","iopub.execute_input":"2022-08-05T10:22:45.061243Z","iopub.status.idle":"2022-08-05T10:22:45.068404Z","shell.execute_reply.started":"2022-08-05T10:22:45.061187Z","shell.execute_reply":"2022-08-05T10:22:45.067282Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Making Dictionaries","metadata":{}},{"cell_type":"code","source":"image_datasets = {\n                    \"train\" : train_data,\n                    \"val\"   : val_data\n                 }\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = train.classes\n\ndataloaders = {\n                \"train\" : train_data_loader,\n                \"val\" : valid_data_loader\n              }","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:46.782298Z","iopub.execute_input":"2022-08-05T10:22:46.782950Z","iopub.status.idle":"2022-08-05T10:22:46.789519Z","shell.execute_reply.started":"2022-08-05T10:22:46.782916Z","shell.execute_reply":"2022-08-05T10:22:46.788219Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Batch Image Visualization","metadata":{}},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.4291, 0.4563, 0.4526])\n    std = np.array([0.2485, 0.2472, 0.2810])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:48.073173Z","iopub.execute_input":"2022-08-05T10:22:48.073988Z","iopub.status.idle":"2022-08-05T10:22:52.514612Z","shell.execute_reply.started":"2022-08-05T10:22:48.073942Z","shell.execute_reply":"2022-08-05T10:22:52.513532Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Configuration of device","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:52.516727Z","iopub.execute_input":"2022-08-05T10:22:52.517016Z","iopub.status.idle":"2022-08-05T10:22:52.525916Z","shell.execute_reply.started":"2022-08-05T10:22:52.516989Z","shell.execute_reply":"2022-08-05T10:22:52.525049Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Defining functions for training and visualizing","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, -1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n    \n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:56.158941Z","iopub.execute_input":"2022-08-05T10:22:56.159334Z","iopub.status.idle":"2022-08-05T10:22:56.171423Z","shell.execute_reply.started":"2022-08-05T10:22:56.159299Z","shell.execute_reply":"2022-08-05T10:22:56.170205Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:22:59.453256Z","iopub.execute_input":"2022-08-05T10:22:59.453990Z","iopub.status.idle":"2022-08-05T10:22:59.462250Z","shell.execute_reply.started":"2022-08-05T10:22:59.453950Z","shell.execute_reply":"2022-08-05T10:22:59.460866Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Using ResNet18","metadata":{}},{"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, len(class_names))\nmodel_ft = model_ft.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:23:07.914523Z","iopub.execute_input":"2022-08-05T10:23:07.914922Z","iopub.status.idle":"2022-08-05T10:23:11.599081Z","shell.execute_reply.started":"2022-08-05T10:23:07.914888Z","shell.execute_reply":"2022-08-05T10:23:11.598103Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model_ft = train_model(\n                model_ft, \n                criterion, \n                optimizer_ft,\n                exp_lr_scheduler,\n                num_epochs = 25\n            )","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-05T10:23:17.915280Z","iopub.execute_input":"2022-08-05T10:23:17.915665Z","iopub.status.idle":"2022-08-05T10:32:35.038793Z","shell.execute_reply.started":"2022-08-05T10:23:17.915635Z","shell.execute_reply":"2022-08-05T10:32:35.036824Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Output Visualizations","metadata":{}},{"cell_type":"code","source":"visualize_model(model_ft)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T10:36:36.761838Z","iopub.execute_input":"2022-08-05T10:36:36.762785Z","iopub.status.idle":"2022-08-05T10:36:37.883700Z","shell.execute_reply.started":"2022-08-05T10:36:36.762747Z","shell.execute_reply":"2022-08-05T10:36:37.882475Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}